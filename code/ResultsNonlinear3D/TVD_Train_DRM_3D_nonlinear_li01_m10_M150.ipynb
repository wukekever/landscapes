{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from math import *\n",
    "import time\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function\n",
    "def activation(x):\n",
    "    return x * torch.sigmoid(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ResNet with three blocks\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,input_width,layer_width):\n",
    "        super(Net,self).__init__()\n",
    "        self.layer_in = torch.nn.Linear(input_width, layer_width)\n",
    "        self.layer1 = torch.nn.Linear(layer_width, layer_width)\n",
    "        self.layer2 = torch.nn.Linear(layer_width, layer_width)\n",
    "        self.layer3 = torch.nn.Linear(layer_width, layer_width)\n",
    "        self.layer4 = torch.nn.Linear(layer_width, layer_width)\n",
    "        self.layer5 = torch.nn.Linear(layer_width, layer_width)\n",
    "        self.layer6 = torch.nn.Linear(layer_width, layer_width)\n",
    "        self.layer_out = torch.nn.Linear(layer_width, 1)\n",
    "    def forward(self,x):\n",
    "        y = self.layer_in(x)\n",
    "        y = y + activation(self.layer2(activation(self.layer1(y)))) # residual block 1\n",
    "        y = y + activation(self.layer4(activation(self.layer3(y)))) # residual block 2\n",
    "        y = y + activation(self.layer6(activation(self.layer5(y)))) # residual block 3\n",
    "        output = self.layer_out(y)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width,layer_width = dimension, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_width,layer_width).cuda() # network for u on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defination of exact solution\n",
    "def u_ex(x):  \n",
    "    x_norm = torch.norm(x, dim = 1) # compute norm of x; dim = 1 - > sum by row\n",
    "    u_x = torch.sin(pi/2*(1-x_norm)).reshape([x.size()[0],1])\n",
    "    return u_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defination of f(x)\n",
    "def f(x):\n",
    "    x_norm = torch.norm(x, dim = 1)\n",
    "    f_temp = 1/4*pi**2*torch.sin(pi/2*(1-x_norm)) + 1/2*pi*(dimension-1)/x_norm*torch.cos(pi/2*(1-x_norm))  \n",
    "    return f_temp.reshape([x.size()[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points by random\n",
    "def generate_sample(data_size):\n",
    "    i = 0\n",
    "    x = torch.tensor([])\n",
    "    while x.size()[0] < data_size:\n",
    "        temp_x = 2*torch.rand(data_size, dimension) - 1\n",
    "        index = torch.where(torch.norm(temp_x, dim = 1) < 1)\n",
    "        temp_x = temp_x[index]\n",
    "        x = torch.cat((x,temp_x),0)\n",
    "    x = x[1:data_size, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    x_norm = torch.norm(x, p = 2, dim = 1) \n",
    "    return (1-x_norm**2).reshape([x.size()[0], 1]) * net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function to DRM by auto differential\n",
    "def loss_function(x):\n",
    "#     x = generate_sample(data_size).cuda()\n",
    "#     x.requires_grad = True\n",
    "    u_hat = model(x)\n",
    "    grad_u_hat = torch.autograd.grad(outputs = u_hat, inputs = x, grad_outputs = torch.ones(u_hat.shape).cuda(), create_graph = True)\n",
    "    grad_u_sq = ((grad_u_hat[0]**2).sum(1)).reshape([len(grad_u_hat[0]), 1])\n",
    "    part = torch.sum(0.5 * grad_u_sq  - f(x) * u_hat)  / len(x)\n",
    "    return part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "x = generate_sample(data_size).cuda()\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(net):\n",
    "    \"\"\" Extract parameters from net, and return a list of tensors\"\"\"\n",
    "    return [p.data for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weights(net, weights, directions=None, step=None):\n",
    "    \"\"\"\n",
    "        Overwrite the network's weights with a specified list of tensors\n",
    "        or change weights along directions with a step size.\n",
    "    \"\"\"\n",
    "    if directions is None:\n",
    "        # You cannot specify a step length without a direction.\n",
    "        for (p, w) in zip(net.parameters(), weights):\n",
    "            p.data.copy_(w.type(type(p.data)))\n",
    "    else:\n",
    "        assert step is not None, 'If a direction is specified then step must be specified as well'\n",
    "\n",
    "        if len(directions) == 2:\n",
    "            dx = directions[0]\n",
    "            dy = directions[1]\n",
    "            changes = [d0*step[0] + d1*step[1] for (d0, d1) in zip(dx, dy)]\n",
    "        else:\n",
    "            changes = [d*step for d in directions[0]]\n",
    "\n",
    "        for (p, w, d) in zip(net.parameters(), weights, changes):\n",
    "            p.data = w + torch.Tensor(d).type(type(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_states(net, states, directions=None, step=None):\n",
    "    \"\"\"\n",
    "        Overwrite the network's state_dict or change it along directions with a step size.\n",
    "    \"\"\"\n",
    "    if directions is None:\n",
    "        net.load_state_dict(states)\n",
    "    else:\n",
    "        assert step is not None, 'If direction is provided then the step must be specified as well'\n",
    "        if len(directions) == 2:\n",
    "            dx = directions[0]\n",
    "            dy = directions[1]\n",
    "            changes = [d0*step[0] + d1*step[1] for (d0, d1) in zip(dx, dy)]\n",
    "        else:\n",
    "            changes = [d*step for d in directions[0]]\n",
    "\n",
    "        new_states = copy.deepcopy(states)\n",
    "        assert (len(new_states) == len(changes))\n",
    "        for (k, v), d in zip(new_states.items(), changes):\n",
    "            d = torch.tensor(d)\n",
    "            v.add_(d.type(v.type()))\n",
    "\n",
    "        net.load_state_dict(new_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_weights(weights):\n",
    "    \"\"\"\n",
    "        Produce a random direction that is a list of random Gaussian tensors\n",
    "        with the same shape as the network's weights, so one direction entry per weight.\n",
    "    \"\"\"\n",
    "    return [torch.randn(w.size()) for w in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_states(states):\n",
    "    \"\"\"\n",
    "        Produce a random direction that is a list of random Gaussian tensors\n",
    "        with the same shape as the network's state_dict(), so one direction entry\n",
    "        per weight, including BN's running_mean/var.\n",
    "    \"\"\"\n",
    "    return [torch.randn(w.size()) for k, w in states.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_weights(weights, weights2):\n",
    "    \"\"\" Produce a direction from 'weights' to 'weights2'.\"\"\"\n",
    "    return [w2 - w for (w, w2) in zip(weights, weights2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_states(states, states2):\n",
    "    \"\"\" Produce a direction from 'states' to 'states2'.\"\"\"\n",
    "    return [v2 - v for (k, v), (k2, v2) in zip(states.items(), states2.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_direction(direction, weights, norm='filter'):\n",
    "    \"\"\"\n",
    "        Rescale the direction so that it has similar norm as their corresponding\n",
    "        model in different levels.\n",
    "        Args:\n",
    "          direction: a variables of the random direction for one layer\n",
    "          weights: a variable of the original model for one layer\n",
    "          norm: normalization method, 'filter' | 'layer' | 'weight'\n",
    "    \"\"\"\n",
    "    if norm == 'filter':\n",
    "        # Rescale the filters (weights in group) in 'direction' so that each\n",
    "        # filter has the same norm as its corresponding filter in 'weights'.\n",
    "        for d, w in zip(direction, weights):\n",
    "            d.mul_(w.norm()/(d.norm() + 1e-10))\n",
    "    elif norm == 'layer':\n",
    "        # Rescale the layer variables in the direction so that each layer has\n",
    "        # the same norm as the layer variables in weights.\n",
    "        direction.mul_(weights.norm()/direction.norm())\n",
    "    elif norm == 'weight':\n",
    "        # Rescale the entries in the direction so that each entry has the same\n",
    "        # scale as the corresponding weight.\n",
    "        direction.mul_(weights)\n",
    "    elif norm == 'dfilter':\n",
    "        # Rescale the entries in the direction so that each filter direction\n",
    "        # has the unit norm.\n",
    "        for d in direction:\n",
    "            d.div_(d.norm() + 1e-10)\n",
    "    elif norm == 'dlayer':\n",
    "        # Rescale the entries in the direction so that each layer direction has\n",
    "        # the unit norm.\n",
    "        direction.div_(direction.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_directions_for_weights(direction, weights, norm='filter', ignore='biasbn'):\n",
    "    \"\"\"\n",
    "        The normalization scales the direction entries according to the entries of weights.\n",
    "    \"\"\"\n",
    "    assert(len(direction) == len(weights))\n",
    "    for d, w in zip(direction, weights):\n",
    "        if d.dim() <= 1:\n",
    "            if ignore == 'biasbn':\n",
    "                d.fill_(0) # ignore directions for weights with 1 dimension\n",
    "            else:\n",
    "                d.copy_(w) # keep directions for weights/bias that are only 1 per node\n",
    "        else:\n",
    "            normalize_direction(d, w, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_directions_for_states(direction, states, norm='filter', ignore='ignore'):\n",
    "    assert(len(direction) == len(states))\n",
    "    for d, (k, w) in zip(direction, states.items()):\n",
    "        if d.dim() <= 1:\n",
    "            if ignore == 'biasbn':\n",
    "                d.fill_(0) # ignore directions for weights with 1 dimension\n",
    "            else:\n",
    "                d.copy_(w) # keep directions for weights/bias that are only 1 per node\n",
    "        else:\n",
    "            normalize_direction(d, w, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_biasbn(directions):\n",
    "    \"\"\" Set bias and bn parameters in directions to zero \"\"\"\n",
    "    for d in directions:\n",
    "        if d.dim() <= 1:\n",
    "            d.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_direction(net, dir_type='weights', ignore='biasbn', norm='filter'):\n",
    "    \"\"\"\n",
    "        Setup a random (normalized) direction with the same dimension as\n",
    "        the weights or states.\n",
    "        Args:\n",
    "          net: the given trained model\n",
    "          dir_type: 'weights' or 'states', type of directions.\n",
    "          ignore: 'biasbn', ignore biases and BN parameters.\n",
    "          norm: direction normalization method, including\n",
    "                'filter\" | 'layer' | 'weight' | 'dlayer' | 'dfilter'\n",
    "        Returns:\n",
    "          direction: a random direction with the same dimension as weights or states.\n",
    "    \"\"\"\n",
    "\n",
    "    # random direction\n",
    "    if dir_type == 'weights':\n",
    "        weights = get_weights(net) # a list of parameters.\n",
    "        direction = get_random_weights(weights)\n",
    "        normalize_directions_for_weights(direction, weights, norm, ignore)\n",
    "    elif dir_type == 'states':\n",
    "        states = net.state_dict() # a dict of parameters, including BN's running mean/var.\n",
    "        direction = get_random_states(states)\n",
    "        normalize_directions_for_states(direction, states, norm, ignore)\n",
    "\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvd(m, l_i):\n",
    "    \n",
    "    # load model parameters\n",
    "    pretrained_dict = torch.load('net_params_DRM.pkl')\n",
    "    \n",
    "    # get state_dict\n",
    "    net_state_dict = net.state_dict()\n",
    "\n",
    "    # remove keys that does not belong to net_state_dict\n",
    "    pretrained_dict_1 = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "\n",
    "    # update dict\n",
    "    net_state_dict.update(pretrained_dict_1)\n",
    "\n",
    "    # set new dict back to net\n",
    "    net.load_state_dict(net_state_dict)\n",
    "    \n",
    "    weights_temp = get_weights(net)\n",
    "    states_temp = net.state_dict()\n",
    "    \n",
    "    step_size = 2 * l_i / m  \n",
    "    grid = np.arange(-l_i, l_i + step_size, step_size)\n",
    "    num_direction = 1\n",
    "    loss_matrix = torch.zeros((num_direction, len(grid)))\n",
    "\n",
    "    for temp in range(num_direction):\n",
    "        weights = weights_temp\n",
    "        states = states_temp\n",
    "        direction_temp = create_random_direction(net, dir_type='weights', ignore='biasbn', norm='filter')\n",
    "        normalize_directions_for_states(direction_temp, states, norm='filter', ignore='ignore')\n",
    "        directions = [direction_temp]\n",
    "\n",
    "        for dx in grid:\n",
    "            itemindex_1 = np.argwhere(grid == dx)\n",
    "            step = dx\n",
    "\n",
    "            set_states(net, states, directions, step)\n",
    "            loss_temp = loss_function(x)\n",
    "            loss_matrix[temp, itemindex_1[0]] = loss_temp\n",
    "            \n",
    "            # clear memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # get state_dict\n",
    "            net_state_dict = net.state_dict()\n",
    "            # remove keys that does not belong to net_state_dict\n",
    "            pretrained_dict_1 = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "            # update dict\n",
    "            net_state_dict.update(pretrained_dict_1)\n",
    "            # set new dict back to net\n",
    "            net.load_state_dict(net_state_dict)\n",
    "            weights_temp = get_weights(net)\n",
    "            states_temp = net.state_dict()\n",
    "\n",
    "    interval_length = grid[-1] - grid[0]\n",
    "    TVD = 0.0\n",
    "    for temp in range(num_direction):\n",
    "        for index in range(loss_matrix.size()[1] - 1):\n",
    "            TVD = TVD + np.abs(float(loss_matrix[temp, index] - loss_matrix[temp, index + 1]))\n",
    "    Max = np.max(loss_matrix.detach().numpy())\n",
    "    Min = np.min(loss_matrix.detach().numpy())\n",
    "\n",
    "    TVD = TVD / interval_length / num_direction / (Max - Min)\n",
    "\n",
    "    return TVD, Max, Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keke/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current direction TVD of DRM is:  7.767434339699378\n",
      "0.6666666666666667 % finished.\n",
      "Current direction TVD of DRM is:  9.020020828791964\n",
      "1.3333333333333335 % finished.\n",
      "Current direction TVD of DRM is:  7.210564603468127\n",
      "2.0 % finished.\n",
      "Current direction TVD of DRM is:  7.970811309081651\n",
      "2.666666666666667 % finished.\n",
      "Current direction TVD of DRM is:  6.680694948332754\n",
      "3.3333333333333335 % finished.\n",
      "Current direction TVD of DRM is:  7.924731903844036\n",
      "4.0 % finished.\n",
      "Current direction TVD of DRM is:  8.496780749498086\n",
      "4.666666666666667 % finished.\n",
      "Current direction TVD of DRM is:  6.8689864307204695\n",
      "5.333333333333334 % finished.\n",
      "Current direction TVD of DRM is:  6.073788104500335\n",
      "6.0 % finished.\n",
      "Current direction TVD of DRM is:  7.860212911142334\n",
      "6.666666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.788212080883409\n",
      "7.333333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.343739629928215\n",
      "8.0 % finished.\n",
      "Current direction TVD of DRM is:  8.257380714650877\n",
      "8.666666666666668 % finished.\n",
      "Current direction TVD of DRM is:  8.010900529717796\n",
      "9.333333333333334 % finished.\n",
      "Current direction TVD of DRM is:  8.150568182883829\n",
      "10.0 % finished.\n",
      "Current direction TVD of DRM is:  7.427475366161966\n",
      "10.666666666666668 % finished.\n",
      "Current direction TVD of DRM is:  6.547798784123397\n",
      "11.333333333333332 % finished.\n",
      "Current direction TVD of DRM is:  7.962508153870535\n",
      "12.0 % finished.\n",
      "Current direction TVD of DRM is:  7.219996133886578\n",
      "12.666666666666668 % finished.\n",
      "Current direction TVD of DRM is:  7.257520941463448\n",
      "13.333333333333334 % finished.\n",
      "Current direction TVD of DRM is:  5.7179711068866625\n",
      "14.000000000000002 % finished.\n",
      "Current direction TVD of DRM is:  4.8194508235479425\n",
      "14.666666666666666 % finished.\n",
      "Current direction TVD of DRM is:  7.134478592228954\n",
      "15.333333333333332 % finished.\n",
      "Current direction TVD of DRM is:  8.214843581286718\n",
      "16.0 % finished.\n",
      "Current direction TVD of DRM is:  7.666569754418955\n",
      "16.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  6.918664131111784\n",
      "17.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  6.9975184164957565\n",
      "18.0 % finished.\n",
      "Current direction TVD of DRM is:  7.95215713773568\n",
      "18.666666666666668 % finished.\n",
      "Current direction TVD of DRM is:  8.24018602601854\n",
      "19.333333333333332 % finished.\n",
      "Current direction TVD of DRM is:  7.562314051623662\n",
      "20.0 % finished.\n",
      "Current direction TVD of DRM is:  7.249285851929464\n",
      "20.666666666666668 % finished.\n",
      "Current direction TVD of DRM is:  7.117647716449018\n",
      "21.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  6.995701703759241\n",
      "22.0 % finished.\n",
      "Current direction TVD of DRM is:  7.116509853008545\n",
      "22.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  8.072115305654325\n",
      "23.333333333333332 % finished.\n",
      "Current direction TVD of DRM is:  8.561982424476781\n",
      "24.0 % finished.\n",
      "Current direction TVD of DRM is:  8.607348278122574\n",
      "24.666666666666668 % finished.\n",
      "Current direction TVD of DRM is:  6.991182853290287\n",
      "25.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  4.628694070807975\n",
      "26.0 % finished.\n",
      "Current direction TVD of DRM is:  7.863777645097689\n",
      "26.666666666666668 % finished.\n",
      "Current direction TVD of DRM is:  7.134732455956952\n",
      "27.333333333333332 % finished.\n",
      "Current direction TVD of DRM is:  7.001478958211779\n",
      "28.000000000000004 % finished.\n",
      "Current direction TVD of DRM is:  6.811689907350853\n",
      "28.666666666666668 % finished.\n",
      "Current direction TVD of DRM is:  7.337426411506089\n",
      "29.333333333333332 % finished.\n",
      "Current direction TVD of DRM is:  7.2680228073995\n",
      "30.0 % finished.\n",
      "Current direction TVD of DRM is:  8.546219283887586\n",
      "30.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  8.812275955825216\n",
      "31.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  7.868352528664309\n",
      "32.0 % finished.\n",
      "Current direction TVD of DRM is:  7.163586725631497\n",
      "32.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  7.751399600063043\n",
      "33.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  6.917731139925279\n",
      "34.0 % finished.\n",
      "Current direction TVD of DRM is:  4.893554197590183\n",
      "34.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  8.671154741285225\n",
      "35.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  8.40359011966687\n",
      "36.0 % finished.\n",
      "Current direction TVD of DRM is:  6.6865089160054945\n",
      "36.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  6.850780643511691\n",
      "37.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  7.547030417891124\n",
      "38.0 % finished.\n",
      "Current direction TVD of DRM is:  7.999238567868265\n",
      "38.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  8.617906345157934\n",
      "39.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.411656897493247\n",
      "40.0 % finished.\n",
      "Current direction TVD of DRM is:  7.361859857339429\n",
      "40.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  7.838417844977488\n",
      "41.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  6.2717065520445265\n",
      "42.0 % finished.\n",
      "Current direction TVD of DRM is:  6.641732333679591\n",
      "42.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  6.526968045233459\n",
      "43.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  8.135562253181181\n",
      "44.0 % finished.\n",
      "Current direction TVD of DRM is:  7.165048587229799\n",
      "44.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  6.582129040445442\n",
      "45.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.360400818486675\n",
      "46.0 % finished.\n",
      "Current direction TVD of DRM is:  6.683880925425616\n",
      "46.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  8.776303871976879\n",
      "47.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  6.660438119096377\n",
      "48.0 % finished.\n",
      "Current direction TVD of DRM is:  7.405428659268882\n",
      "48.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  8.597197502163702\n",
      "49.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  7.821767306055352\n",
      "50.0 % finished.\n",
      "Current direction TVD of DRM is:  7.03507483507424\n",
      "50.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.709422046575739\n",
      "51.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  8.05787479918118\n",
      "52.0 % finished.\n",
      "Current direction TVD of DRM is:  8.364621226487445\n",
      "52.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  6.249577009681902\n",
      "53.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  7.483463502895483\n",
      "54.0 % finished.\n",
      "Current direction TVD of DRM is:  8.991193201461371\n",
      "54.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  7.896416080709846\n",
      "55.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  7.5521064041493835\n",
      "56.00000000000001 % finished.\n",
      "Current direction TVD of DRM is:  4.7975080257200755\n",
      "56.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  7.60887921930072\n",
      "57.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  7.8135091537138175\n",
      "57.99999999999999 % finished.\n",
      "Current direction TVD of DRM is:  8.983109006068284\n",
      "58.666666666666664 % finished.\n",
      "Current direction TVD of DRM is:  8.923132426485314\n",
      "59.333333333333336 % finished.\n",
      "Current direction TVD of DRM is:  8.214439004504175\n",
      "60.0 % finished.\n",
      "Current direction TVD of DRM is:  6.630794188283911\n",
      "60.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.041701789611743\n",
      "61.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.041369652826443\n",
      "62.0 % finished.\n",
      "Current direction TVD of DRM is:  7.6818210684903585\n",
      "62.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  8.233171569683991\n",
      "63.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  8.652902449247671\n",
      "64.0 % finished.\n",
      "Current direction TVD of DRM is:  8.85674912499348\n",
      "64.66666666666666 % finished.\n",
      "Current direction TVD of DRM is:  7.040064480901136\n",
      "65.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  8.906186981336285\n",
      "66.0 % finished.\n",
      "Current direction TVD of DRM is:  7.531470800263061\n",
      "66.66666666666666 % finished.\n",
      "Current direction TVD of DRM is:  9.00084077605815\n",
      "67.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.906353136669169\n",
      "68.0 % finished.\n",
      "Current direction TVD of DRM is:  6.598012684447194\n",
      "68.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  8.73889526923129\n",
      "69.33333333333334 % finished.\n",
      "Current direction TVD of DRM is:  7.361701185692422\n",
      "70.0 % finished.\n",
      "Current direction TVD of DRM is:  8.35313900176945\n",
      "70.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.7735676744211055\n",
      "71.33333333333334 % finished.\n",
      "Current direction TVD of DRM is:  8.665977360896813\n",
      "72.0 % finished.\n",
      "Current direction TVD of DRM is:  8.003884468609506\n",
      "72.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.1038747888029325\n",
      "73.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.3426771353558955\n",
      "74.0 % finished.\n",
      "Current direction TVD of DRM is:  6.950597912995137\n",
      "74.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.2355245661592855\n",
      "75.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  6.797121434140532\n",
      "76.0 % finished.\n",
      "Current direction TVD of DRM is:  7.077071664396175\n",
      "76.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.510933882295495\n",
      "77.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  8.094381009753622\n",
      "78.0 % finished.\n",
      "Current direction TVD of DRM is:  7.672287408778454\n",
      "78.66666666666666 % finished.\n",
      "Current direction TVD of DRM is:  7.175809099214151\n",
      "79.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  8.075620545948144\n",
      "80.0 % finished.\n",
      "Current direction TVD of DRM is:  8.505689973309641\n",
      "80.66666666666666 % finished.\n",
      "Current direction TVD of DRM is:  7.017316286833504\n",
      "81.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.990826007975603\n",
      "82.0 % finished.\n",
      "Current direction TVD of DRM is:  6.843108633785356\n",
      "82.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.214981134475963\n",
      "83.33333333333334 % finished.\n",
      "Current direction TVD of DRM is:  8.570118772543227\n",
      "84.0 % finished.\n",
      "Current direction TVD of DRM is:  6.759225653313099\n",
      "84.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  8.829723371456415\n",
      "85.33333333333334 % finished.\n",
      "Current direction TVD of DRM is:  6.66854137000065\n",
      "86.0 % finished.\n",
      "Current direction TVD of DRM is:  8.923755481966115\n",
      "86.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.284203805071503\n",
      "87.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.666305865078872\n",
      "88.0 % finished.\n",
      "Current direction TVD of DRM is:  6.8638208798976335\n",
      "88.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  6.959063078576621\n",
      "89.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.307395665229328\n",
      "90.0 % finished.\n",
      "Current direction TVD of DRM is:  6.864567617009377\n",
      "90.66666666666666 % finished.\n",
      "Current direction TVD of DRM is:  8.784831388115009\n",
      "91.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  7.87293832774778\n",
      "92.0 % finished.\n",
      "Current direction TVD of DRM is:  6.899641009123294\n",
      "92.66666666666666 % finished.\n",
      "Current direction TVD of DRM is:  6.895225511391\n",
      "93.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  5.073006071243718\n",
      "94.0 % finished.\n",
      "Current direction TVD of DRM is:  6.594446872145352\n",
      "94.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.795082031809334\n",
      "95.33333333333334 % finished.\n",
      "Current direction TVD of DRM is:  7.290651966802742\n",
      "96.0 % finished.\n",
      "Current direction TVD of DRM is:  8.510178055540312\n",
      "96.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.622042303985346\n",
      "97.33333333333334 % finished.\n",
      "Current direction TVD of DRM is:  6.248419152220364\n",
      "98.0 % finished.\n",
      "Current direction TVD of DRM is:  8.126121466577747\n",
      "98.66666666666667 % finished.\n",
      "Current direction TVD of DRM is:  7.437671423297784\n",
      "99.33333333333333 % finished.\n",
      "Current direction TVD of DRM is:  6.641065473094703\n",
      "100.0 % finished.\n",
      "All directions average TVD of DRM is:  7.497243320073305\n",
      "Variance TVD of DRM is:  0.8795944119065631\n",
      "Total time costs:  40.96502494812012 seconds\n"
     ]
    }
   ],
   "source": [
    "M = 150\n",
    "m = 10\n",
    "l_i = 0.1\n",
    "\n",
    "TVD_DRM = 0.0\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "Max = []\n",
    "Min = []\n",
    "Result = []\n",
    "\n",
    "for count in range(M):\n",
    "    TVD_temp, Max_temp, Min_temp = tvd(m, l_i)\n",
    "#     print(Max_temp, Min_temp)\n",
    "    Max.append(Max_temp)\n",
    "    Min.append(Min_temp)\n",
    "    Result.append(TVD_temp)\n",
    "    print('Current direction TVD of DRM is: ', TVD_temp)\n",
    "    TVD_DRM = TVD_DRM + TVD_temp\n",
    "    print((count + 1) / M * 100, '% finished.')\n",
    "\n",
    "# print('Max of all is: ', np.max(Max))\n",
    "# print('Min of all is: ', np.min(Min))\n",
    "\n",
    "TVD_DRM = TVD_DRM / M \n",
    "print('All directions average TVD of DRM is: ', TVD_DRM)\n",
    "\n",
    "print('Variance TVD of DRM is: ', np.sqrt(np.var(Result, ddof = 1)))\n",
    "\n",
    "time_end = time.time()\n",
    "print('Total time costs: ', time_end - time_start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
