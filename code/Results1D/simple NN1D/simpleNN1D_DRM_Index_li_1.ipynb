{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from math import *\n",
    "import time\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,input_width,layer_width):\n",
    "        super(Net,self).__init__()\n",
    "        self.layer_out = torch.nn.Linear(layer_width, 1)\n",
    "    def forward(self,x):\n",
    "        output = self.layer_out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width,layer_width = dimension, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_width,layer_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defination of exact solution\n",
    "def u_ex(x):     \n",
    "    u_temp = 2*x**3 - x**2 - x\n",
    "    return u_temp.reshape([x.size()[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defination of f(x)\n",
    "def f(x):\n",
    "    f_temp = -(12*x - 2)\n",
    "    return f_temp.reshape([x.size()[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points by random\n",
    "def generate_sample(data_size):\n",
    "    sample_temp = torch.rand(data_size, dimension)\n",
    "    return sample_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    x_temp = x\n",
    "    D_x_0 = torch.prod(x_temp, axis = 1).reshape([x.size()[0], 1]) \n",
    "    D_x_1 = torch.prod(1.0 - x_temp, axis = 1).reshape([x.size()[0], 1]) \n",
    "    model_u_temp = D_x_0 * D_x_1 * net(x)\n",
    "    return model_u_temp.reshape([x.size()[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function to DRM by auto differential\n",
    "def loss_function(x):\n",
    "#     x = generate_sample(data_size).cuda()\n",
    "#     x.requires_grad = True\n",
    "    u_hat = model(x)\n",
    "    grad_u_hat = torch.autograd.grad(outputs = u_hat, inputs = x, grad_outputs = torch.ones(u_hat.shape), create_graph = True)\n",
    "    grad_u_sq = ((grad_u_hat[0]**2).sum(1)).reshape([len(grad_u_hat[0]), 1])\n",
    "    part = torch.sum(0.5 * grad_u_sq  - f(x) * u_hat)  / len(x)\n",
    "    return part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 10000\n",
    "x = generate_sample(data_size)\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(net):\n",
    "    \"\"\" Extract parameters from net, and return a list of tensors\"\"\"\n",
    "    return [p.data for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weights(net, weights, directions=None, step=None):\n",
    "    \"\"\"\n",
    "        Overwrite the network's weights with a specified list of tensors\n",
    "        or change weights along directions with a step size.\n",
    "    \"\"\"\n",
    "    if directions is None:\n",
    "        # You cannot specify a step length without a direction.\n",
    "        for (p, w) in zip(net.parameters(), weights):\n",
    "            p.data.copy_(w.type(type(p.data)))\n",
    "    else:\n",
    "        assert step is not None, 'If a direction is specified then step must be specified as well'\n",
    "\n",
    "        if len(directions) == 2:\n",
    "            dx = directions[0]\n",
    "            dy = directions[1]\n",
    "            changes = [d0*step[0] + d1*step[1] for (d0, d1) in zip(dx, dy)]\n",
    "        else:\n",
    "            changes = [d*step for d in directions[0]]\n",
    "\n",
    "        for (p, w, d) in zip(net.parameters(), weights, changes):\n",
    "            p.data = w + torch.Tensor(d).type(type(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_states(net, states, directions=None, step=None):\n",
    "    \"\"\"\n",
    "        Overwrite the network's state_dict or change it along directions with a step size.\n",
    "    \"\"\"\n",
    "    if directions is None:\n",
    "        net.load_state_dict(states)\n",
    "    else:\n",
    "        assert step is not None, 'If direction is provided then the step must be specified as well'\n",
    "        if len(directions) == 2:\n",
    "            dx = directions[0]\n",
    "            dy = directions[1]\n",
    "            changes = [d0*step[0] + d1*step[1] for (d0, d1) in zip(dx, dy)]\n",
    "        else:\n",
    "            changes = [d*step for d in directions[0]]\n",
    "\n",
    "        new_states = copy.deepcopy(states)\n",
    "        assert (len(new_states) == len(changes))\n",
    "        for (k, v), d in zip(new_states.items(), changes):\n",
    "            d = torch.tensor(d)\n",
    "            v.add_(d.type(v.type()))\n",
    "\n",
    "        net.load_state_dict(new_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_weights(weights):\n",
    "    \"\"\"\n",
    "        Produce a random direction that is a list of random Gaussian tensors\n",
    "        with the same shape as the network's weights, so one direction entry per weight.\n",
    "    \"\"\"\n",
    "    return [torch.randn(w.size()) for w in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_states(states):\n",
    "    \"\"\"\n",
    "        Produce a random direction that is a list of random Gaussian tensors\n",
    "        with the same shape as the network's state_dict(), so one direction entry\n",
    "        per weight, including BN's running_mean/var.\n",
    "    \"\"\"\n",
    "    return [torch.randn(w.size()) for k, w in states.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_weights(weights, weights2):\n",
    "    \"\"\" Produce a direction from 'weights' to 'weights2'.\"\"\"\n",
    "    return [w2 - w for (w, w2) in zip(weights, weights2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_states(states, states2):\n",
    "    \"\"\" Produce a direction from 'states' to 'states2'.\"\"\"\n",
    "    return [v2 - v for (k, v), (k2, v2) in zip(states.items(), states2.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_direction(direction, weights, norm='filter'):\n",
    "    \"\"\"\n",
    "        Rescale the direction so that it has similar norm as their corresponding\n",
    "        model in different levels.\n",
    "        Args:\n",
    "          direction: a variables of the random direction for one layer\n",
    "          weights: a variable of the original model for one layer\n",
    "          norm: normalization method, 'filter' | 'layer' | 'weight'\n",
    "    \"\"\"\n",
    "    if norm == 'filter':\n",
    "        # Rescale the filters (weights in group) in 'direction' so that each\n",
    "        # filter has the same norm as its corresponding filter in 'weights'.\n",
    "        for d, w in zip(direction, weights):\n",
    "            d.mul_(w.norm()/(d.norm() + 1e-10))\n",
    "    elif norm == 'layer':\n",
    "        # Rescale the layer variables in the direction so that each layer has\n",
    "        # the same norm as the layer variables in weights.\n",
    "        direction.mul_(weights.norm()/direction.norm())\n",
    "    elif norm == 'weight':\n",
    "        # Rescale the entries in the direction so that each entry has the same\n",
    "        # scale as the corresponding weight.\n",
    "        direction.mul_(weights)\n",
    "    elif norm == 'dfilter':\n",
    "        # Rescale the entries in the direction so that each filter direction\n",
    "        # has the unit norm.\n",
    "        for d in direction:\n",
    "            d.div_(d.norm() + 1e-10)\n",
    "    elif norm == 'dlayer':\n",
    "        # Rescale the entries in the direction so that each layer direction has\n",
    "        # the unit norm.\n",
    "        direction.div_(direction.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_directions_for_weights(direction, weights, norm='filter', ignore='biasbn'):\n",
    "    \"\"\"\n",
    "        The normalization scales the direction entries according to the entries of weights.\n",
    "    \"\"\"\n",
    "    assert(len(direction) == len(weights))\n",
    "    for d, w in zip(direction, weights):\n",
    "        if d.dim() <= 1:\n",
    "            if ignore == 'biasbn':\n",
    "                d.fill_(0) # ignore directions for weights with 1 dimension\n",
    "            else:\n",
    "                d.copy_(w) # keep directions for weights/bias that are only 1 per node\n",
    "        else:\n",
    "            normalize_direction(d, w, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_directions_for_states(direction, states, norm='filter', ignore='ignore'):\n",
    "    assert(len(direction) == len(states))\n",
    "    for d, (k, w) in zip(direction, states.items()):\n",
    "        if d.dim() <= 1:\n",
    "            if ignore == 'biasbn':\n",
    "                d.fill_(0) # ignore directions for weights with 1 dimension\n",
    "            else:\n",
    "                d.copy_(w) # keep directions for weights/bias that are only 1 per node\n",
    "        else:\n",
    "            normalize_direction(d, w, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_biasbn(directions):\n",
    "    \"\"\" Set bias and bn parameters in directions to zero \"\"\"\n",
    "    for d in directions:\n",
    "        if d.dim() <= 1:\n",
    "            d.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_direction(net, dir_type='weights', ignore='biasbn', norm='filter'):\n",
    "    \"\"\"\n",
    "        Setup a random (normalized) direction with the same dimension as\n",
    "        the weights or states.\n",
    "        Args:\n",
    "          net: the given trained model\n",
    "          dir_type: 'weights' or 'states', type of directions.\n",
    "          ignore: 'biasbn', ignore biases and BN parameters.\n",
    "          norm: direction normalization method, including\n",
    "                'filter\" | 'layer' | 'weight' | 'dlayer' | 'dfilter'\n",
    "        Returns:\n",
    "          direction: a random direction with the same dimension as weights or states.\n",
    "    \"\"\"\n",
    "\n",
    "    # random direction\n",
    "    if dir_type == 'weights':\n",
    "        weights = get_weights(net) # a list of parameters.\n",
    "        direction = get_random_weights(weights)\n",
    "        normalize_directions_for_weights(direction, weights, norm, ignore)\n",
    "    elif dir_type == 'states':\n",
    "        states = net.state_dict() # a dict of parameters, including BN's running mean/var.\n",
    "        direction = get_random_states(states)\n",
    "        normalize_directions_for_states(direction, states, norm, ignore)\n",
    "\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvd(m, l_i):\n",
    "    \n",
    "    # load model parameters\n",
    "    pretrained_dict = torch.load('net_params_DRM.pkl')\n",
    "    \n",
    "    # get state_dict\n",
    "    net_state_dict = net.state_dict()\n",
    "\n",
    "    # remove keys that does not belong to net_state_dict\n",
    "    pretrained_dict_1 = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "\n",
    "    # update dict\n",
    "    net_state_dict.update(pretrained_dict_1)\n",
    "\n",
    "    # set new dict back to net\n",
    "    net.load_state_dict(net_state_dict)\n",
    "    \n",
    "    weights_temp = get_weights(net)\n",
    "    states_temp = net.state_dict()\n",
    "    \n",
    "    step_size = 2 * l_i / m  \n",
    "    grid = np.arange(-l_i, l_i + step_size, step_size)\n",
    "    num_direction = 1\n",
    "    loss_matrix = torch.zeros((num_direction, len(grid)))\n",
    "\n",
    "    for temp in range(num_direction):\n",
    "        weights = weights_temp\n",
    "        states = states_temp\n",
    "        direction_temp = create_random_direction(net, dir_type='weights', ignore='biasbn', norm='filter')\n",
    "        normalize_directions_for_states(direction_temp, states, norm='filter', ignore='ignore')\n",
    "        directions = [direction_temp]\n",
    "\n",
    "        for dx in grid:\n",
    "            itemindex_1 = np.argwhere(grid == dx)\n",
    "            step = dx\n",
    "\n",
    "            set_states(net, states, directions, step)\n",
    "            loss_temp = loss_function(x)\n",
    "            loss_matrix[temp, itemindex_1[0]] = loss_temp\n",
    "            \n",
    "            # clear memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # get state_dict\n",
    "            net_state_dict = net.state_dict()\n",
    "            # remove keys that does not belong to net_state_dict\n",
    "            pretrained_dict_1 = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "            # update dict\n",
    "            net_state_dict.update(pretrained_dict_1)\n",
    "            # set new dict back to net\n",
    "            net.load_state_dict(net_state_dict)\n",
    "            weights_temp = get_weights(net)\n",
    "            states_temp = net.state_dict()\n",
    "\n",
    "    interval_length = grid[-1] - grid[0]\n",
    "    TVD = 0.0\n",
    "    for temp in range(num_direction):\n",
    "        for index in range(loss_matrix.size()[1] - 1):\n",
    "            TVD = TVD + np.abs(float(loss_matrix[temp, index] - loss_matrix[temp, index + 1]))\n",
    "    Max = np.max(loss_matrix.detach().numpy())\n",
    "    Min = np.min(loss_matrix.detach().numpy())\n",
    "\n",
    "    TVD = TVD / interval_length / num_direction / (Max - Min)\n",
    "\n",
    "    return TVD, Max, Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keke/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "2.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "4.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "6.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "8.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "10.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "12.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "14.000000000000002 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "16.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "18.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "20.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "22.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "24.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "26.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "28.000000000000004 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "30.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "32.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614644\n",
      "34.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "36.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "38.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "40.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "42.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "44.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "46.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "48.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614644\n",
      "50.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "52.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614644\n",
      "54.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "56.00000000000001 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "57.99999999999999 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "60.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614644\n",
      "62.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "64.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614644\n",
      "66.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "68.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "70.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "72.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "74.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614644\n",
      "76.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "78.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614644\n",
      "80.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614644\n",
      "82.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "84.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "86.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "88.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "90.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "92.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "94.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "96.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9959748008404222\n",
      "98.0 % finished.\n",
      "Current direction TVD of DRM is:  0.9825120093614648\n",
      "100.0 % finished.\n",
      "All directions average TVD of DRM is:  0.9881663817826266\n",
      "Variance TVD of DRM is:  0.006712135626356745\n",
      "Total time costs:  56.26852107048035 seconds\n"
     ]
    }
   ],
   "source": [
    "M = 50\n",
    "m = 50\n",
    "l_i = 1.0\n",
    "\n",
    "TVD_DGM = 0.0\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "Max = []\n",
    "Min = []\n",
    "Result = []\n",
    "\n",
    "for count in range(M):\n",
    "    TVD_temp, Max_temp, Min_temp = tvd(m, l_i)\n",
    "#     print(Max_temp, Min_temp)\n",
    "    Max.append(Max_temp)\n",
    "    Min.append(Min_temp)\n",
    "    Result.append(TVD_temp)\n",
    "    print('Current direction TVD of DRM is: ', TVD_temp)\n",
    "    TVD_DGM = TVD_DGM + TVD_temp\n",
    "    print((count + 1) / M * 100, '% finished.')\n",
    "\n",
    "# print('Max of all is: ', np.max(Max))\n",
    "# print('Min of all is: ', np.min(Min))\n",
    "\n",
    "TVD_DGM = TVD_DGM / M \n",
    "print('All directions average TVD of DRM is: ', TVD_DGM)\n",
    "\n",
    "print('Variance TVD of DRM is: ', np.sqrt(np.var(Result, ddof = 1)))\n",
    "\n",
    "time_end = time.time()\n",
    "print('Total time costs: ', time_end - time_start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt \n",
    "import matplotlib.pyplot as mp\n",
    "import numpy as np\n",
    "plt.style.use(\"seaborn-dark\") # print(plt.style.available)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirc = [i + 1 for i in range(len(Result))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt \n",
    "import matplotlib.pyplot as mp\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(\"seaborn-dark\")\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "ax.set_ylim(0.965, 0.99)\n",
    "\n",
    "plt.scatter(dirc, Result, c = 'red')\n",
    "plt.xlabel('Direction index', size = 12)\n",
    "plt.ylabel('TV', size = 12)\n",
    "plt.grid(True)\n",
    "# plt.savefig(\"Relative_error.eps\", dpi = 120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('DRM.npy', Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
