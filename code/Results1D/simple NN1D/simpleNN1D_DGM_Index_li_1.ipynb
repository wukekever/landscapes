{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from math import *\n",
    "import time\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,input_width,layer_width):\n",
    "        super(Net,self).__init__()\n",
    "        self.layer_out = torch.nn.Linear(layer_width, 1)\n",
    "    def forward(self,x):\n",
    "        output = self.layer_out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width,layer_width = dimension, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_width,layer_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defination of exact solution\n",
    "def u_ex(x):     \n",
    "    u_temp = 2*x**3 - x**2 - x\n",
    "    return u_temp.reshape([x.size()[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defination of f(x)\n",
    "def f(x):\n",
    "    f_temp = -(12*x - 2)\n",
    "    return f_temp.reshape([x.size()[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points by random\n",
    "def generate_sample(data_size):\n",
    "    sample_temp = torch.rand(data_size, dimension)\n",
    "    return sample_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    x_temp = x\n",
    "    D_x_0 = torch.prod(x_temp, axis = 1).reshape([x.size()[0], 1]) \n",
    "    D_x_1 = torch.prod(1.0 - x_temp, axis = 1).reshape([x.size()[0], 1]) \n",
    "    model_u_temp = D_x_0 * D_x_1 * net(x)\n",
    "    return model_u_temp.reshape([x.size()[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function to DGM by auto differential\n",
    "def loss_function(x):\n",
    "#     x = generate_sample(data_size).cuda()\n",
    "#     x.requires_grad = True\n",
    "    u_hat = model(x)\n",
    "    grad_u_hat = torch.autograd.grad(outputs = u_hat, inputs = x, grad_outputs = torch.ones(u_hat.shape), create_graph = True)\n",
    "    laplace_u = torch.zeros([len(grad_u_hat[0]), 1])\n",
    "    for index in range(dimension):\n",
    "        p_temp = grad_u_hat[0][:, index].reshape([len(grad_u_hat[0]), 1])\n",
    "        temp = torch.autograd.grad(outputs = p_temp, inputs = x, grad_outputs = torch.ones(p_temp.shape), create_graph = True, allow_unused = True)[0]\n",
    "        laplace_u = temp[:, index].reshape([len(grad_u_hat[0]), 1]) + laplace_u\n",
    "        part_2 = torch.sum((-laplace_u - f(x))**2)  / len(x)\n",
    "    return part_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 10000\n",
    "x = generate_sample(data_size)\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(net):\n",
    "    \"\"\" Extract parameters from net, and return a list of tensors\"\"\"\n",
    "    return [p.data for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weights(net, weights, directions=None, step=None):\n",
    "    \"\"\"\n",
    "        Overwrite the network's weights with a specified list of tensors\n",
    "        or change weights along directions with a step size.\n",
    "    \"\"\"\n",
    "    if directions is None:\n",
    "        # You cannot specify a step length without a direction.\n",
    "        for (p, w) in zip(net.parameters(), weights):\n",
    "            p.data.copy_(w.type(type(p.data)))\n",
    "    else:\n",
    "        assert step is not None, 'If a direction is specified then step must be specified as well'\n",
    "\n",
    "        if len(directions) == 2:\n",
    "            dx = directions[0]\n",
    "            dy = directions[1]\n",
    "            changes = [d0*step[0] + d1*step[1] for (d0, d1) in zip(dx, dy)]\n",
    "        else:\n",
    "            changes = [d*step for d in directions[0]]\n",
    "\n",
    "        for (p, w, d) in zip(net.parameters(), weights, changes):\n",
    "            p.data = w + torch.Tensor(d).type(type(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_states(net, states, directions=None, step=None):\n",
    "    \"\"\"\n",
    "        Overwrite the network's state_dict or change it along directions with a step size.\n",
    "    \"\"\"\n",
    "    if directions is None:\n",
    "        net.load_state_dict(states)\n",
    "    else:\n",
    "        assert step is not None, 'If direction is provided then the step must be specified as well'\n",
    "        if len(directions) == 2:\n",
    "            dx = directions[0]\n",
    "            dy = directions[1]\n",
    "            changes = [d0*step[0] + d1*step[1] for (d0, d1) in zip(dx, dy)]\n",
    "        else:\n",
    "            changes = [d*step for d in directions[0]]\n",
    "\n",
    "        new_states = copy.deepcopy(states)\n",
    "        assert (len(new_states) == len(changes))\n",
    "        for (k, v), d in zip(new_states.items(), changes):\n",
    "            d = torch.tensor(d)\n",
    "            v.add_(d.type(v.type()))\n",
    "\n",
    "        net.load_state_dict(new_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_weights(weights):\n",
    "    \"\"\"\n",
    "        Produce a random direction that is a list of random Gaussian tensors\n",
    "        with the same shape as the network's weights, so one direction entry per weight.\n",
    "    \"\"\"\n",
    "    return [torch.randn(w.size()) for w in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_states(states):\n",
    "    \"\"\"\n",
    "        Produce a random direction that is a list of random Gaussian tensors\n",
    "        with the same shape as the network's state_dict(), so one direction entry\n",
    "        per weight, including BN's running_mean/var.\n",
    "    \"\"\"\n",
    "    return [torch.randn(w.size()) for k, w in states.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_weights(weights, weights2):\n",
    "    \"\"\" Produce a direction from 'weights' to 'weights2'.\"\"\"\n",
    "    return [w2 - w for (w, w2) in zip(weights, weights2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_states(states, states2):\n",
    "    \"\"\" Produce a direction from 'states' to 'states2'.\"\"\"\n",
    "    return [v2 - v for (k, v), (k2, v2) in zip(states.items(), states2.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_direction(direction, weights, norm='filter'):\n",
    "    \"\"\"\n",
    "        Rescale the direction so that it has similar norm as their corresponding\n",
    "        model in different levels.\n",
    "        Args:\n",
    "          direction: a variables of the random direction for one layer\n",
    "          weights: a variable of the original model for one layer\n",
    "          norm: normalization method, 'filter' | 'layer' | 'weight'\n",
    "    \"\"\"\n",
    "    if norm == 'filter':\n",
    "        # Rescale the filters (weights in group) in 'direction' so that each\n",
    "        # filter has the same norm as its corresponding filter in 'weights'.\n",
    "        for d, w in zip(direction, weights):\n",
    "            d.mul_(w.norm()/(d.norm() + 1e-10))\n",
    "    elif norm == 'layer':\n",
    "        # Rescale the layer variables in the direction so that each layer has\n",
    "        # the same norm as the layer variables in weights.\n",
    "        direction.mul_(weights.norm()/direction.norm())\n",
    "    elif norm == 'weight':\n",
    "        # Rescale the entries in the direction so that each entry has the same\n",
    "        # scale as the corresponding weight.\n",
    "        direction.mul_(weights)\n",
    "    elif norm == 'dfilter':\n",
    "        # Rescale the entries in the direction so that each filter direction\n",
    "        # has the unit norm.\n",
    "        for d in direction:\n",
    "            d.div_(d.norm() + 1e-10)\n",
    "    elif norm == 'dlayer':\n",
    "        # Rescale the entries in the direction so that each layer direction has\n",
    "        # the unit norm.\n",
    "        direction.div_(direction.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_directions_for_weights(direction, weights, norm='filter', ignore='biasbn'):\n",
    "    \"\"\"\n",
    "        The normalization scales the direction entries according to the entries of weights.\n",
    "    \"\"\"\n",
    "    assert(len(direction) == len(weights))\n",
    "    for d, w in zip(direction, weights):\n",
    "        if d.dim() <= 1:\n",
    "            if ignore == 'biasbn':\n",
    "                d.fill_(0) # ignore directions for weights with 1 dimension\n",
    "            else:\n",
    "                d.copy_(w) # keep directions for weights/bias that are only 1 per node\n",
    "        else:\n",
    "            normalize_direction(d, w, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_directions_for_states(direction, states, norm='filter', ignore='ignore'):\n",
    "    assert(len(direction) == len(states))\n",
    "    for d, (k, w) in zip(direction, states.items()):\n",
    "        if d.dim() <= 1:\n",
    "            if ignore == 'biasbn':\n",
    "                d.fill_(0) # ignore directions for weights with 1 dimension\n",
    "            else:\n",
    "                d.copy_(w) # keep directions for weights/bias that are only 1 per node\n",
    "        else:\n",
    "            normalize_direction(d, w, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_biasbn(directions):\n",
    "    \"\"\" Set bias and bn parameters in directions to zero \"\"\"\n",
    "    for d in directions:\n",
    "        if d.dim() <= 1:\n",
    "            d.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_direction(net, dir_type='weights', ignore='biasbn', norm='filter'):\n",
    "    \"\"\"\n",
    "        Setup a random (normalized) direction with the same dimension as\n",
    "        the weights or states.\n",
    "        Args:\n",
    "          net: the given trained model\n",
    "          dir_type: 'weights' or 'states', type of directions.\n",
    "          ignore: 'biasbn', ignore biases and BN parameters.\n",
    "          norm: direction normalization method, including\n",
    "                'filter\" | 'layer' | 'weight' | 'dlayer' | 'dfilter'\n",
    "        Returns:\n",
    "          direction: a random direction with the same dimension as weights or states.\n",
    "    \"\"\"\n",
    "\n",
    "    # random direction\n",
    "    if dir_type == 'weights':\n",
    "        weights = get_weights(net) # a list of parameters.\n",
    "        direction = get_random_weights(weights)\n",
    "        normalize_directions_for_weights(direction, weights, norm, ignore)\n",
    "    elif dir_type == 'states':\n",
    "        states = net.state_dict() # a dict of parameters, including BN's running mean/var.\n",
    "        direction = get_random_states(states)\n",
    "        normalize_directions_for_states(direction, states, norm, ignore)\n",
    "\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvd(m, l_i):\n",
    "    \n",
    "    # load model parameters\n",
    "    pretrained_dict = torch.load('net_params_DGM.pkl')\n",
    "    \n",
    "    # get state_dict\n",
    "    net_state_dict = net.state_dict()\n",
    "\n",
    "    # remove keys that does not belong to net_state_dict\n",
    "    pretrained_dict_1 = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "\n",
    "    # update dict\n",
    "    net_state_dict.update(pretrained_dict_1)\n",
    "\n",
    "    # set new dict back to net\n",
    "    net.load_state_dict(net_state_dict)\n",
    "    \n",
    "    weights_temp = get_weights(net)\n",
    "    states_temp = net.state_dict()\n",
    "    \n",
    "    step_size = 2 * l_i / m  \n",
    "    grid = np.arange(-l_i, l_i + step_size, step_size)\n",
    "    num_direction = 1\n",
    "    loss_matrix = torch.zeros((num_direction, len(grid)))\n",
    "\n",
    "    for temp in range(num_direction):\n",
    "        weights = weights_temp\n",
    "        states = states_temp\n",
    "        direction_temp = create_random_direction(net, dir_type='weights', ignore='biasbn', norm='filter')\n",
    "        normalize_directions_for_states(direction_temp, states, norm='filter', ignore='ignore')\n",
    "        directions = [direction_temp]\n",
    "\n",
    "        for dx in grid:\n",
    "            itemindex_1 = np.argwhere(grid == dx)\n",
    "            step = dx\n",
    "\n",
    "            set_states(net, states, directions, step)\n",
    "            loss_temp = loss_function(x)\n",
    "            loss_matrix[temp, itemindex_1[0]] = loss_temp\n",
    "            \n",
    "            # clear memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # get state_dict\n",
    "            net_state_dict = net.state_dict()\n",
    "            # remove keys that does not belong to net_state_dict\n",
    "            pretrained_dict_1 = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "            # update dict\n",
    "            net_state_dict.update(pretrained_dict_1)\n",
    "            # set new dict back to net\n",
    "            net.load_state_dict(net_state_dict)\n",
    "            weights_temp = get_weights(net)\n",
    "            states_temp = net.state_dict()\n",
    "\n",
    "    interval_length = grid[-1] - grid[0]\n",
    "    TVD = 0.0\n",
    "    for temp in range(num_direction):\n",
    "        for index in range(loss_matrix.size()[1] - 1):\n",
    "            TVD = TVD + np.abs(float(loss_matrix[temp, index] - loss_matrix[temp, index + 1]))\n",
    "    Max = np.max(loss_matrix.detach().numpy())\n",
    "    Min = np.min(loss_matrix.detach().numpy())\n",
    "\n",
    "    TVD = TVD / interval_length / num_direction / (Max - Min)\n",
    "\n",
    "    return TVD, Max, Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keke/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "2.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "4.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "6.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "8.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "10.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "12.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "14.000000000000002 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "16.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "18.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "20.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "22.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "24.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "26.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "28.000000000000004 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "30.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "32.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "34.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "36.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "38.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "40.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "42.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "44.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "46.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "48.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "50.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "52.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "54.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "56.00000000000001 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "57.99999999999999 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "60.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "62.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "64.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "66.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "68.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "70.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "72.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "74.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "76.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "78.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "80.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "82.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "84.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "86.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "88.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "90.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "92.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "94.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "96.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999999038035886\n",
      "98.0 % finished.\n",
      "Current direction TVD of DGM is:  0.9999988329499364\n",
      "100.0 % finished.\n",
      "All directions average TVD of DGM is:  0.9999992827084705\n",
      "Variance TVD of DGM is:  5.338948434844352e-07\n",
      "Total time costs:  93.69633960723877 seconds\n"
     ]
    }
   ],
   "source": [
    "M = 50\n",
    "m = 50\n",
    "l_i = 1.0\n",
    "\n",
    "TVD_DGM = 0.0\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "Max = []\n",
    "Min = []\n",
    "Result = []\n",
    "\n",
    "for count in range(M):\n",
    "    TVD_temp, Max_temp, Min_temp = tvd(m, l_i)\n",
    "#     print(Max_temp, Min_temp)\n",
    "    Max.append(Max_temp)\n",
    "    Min.append(Min_temp)\n",
    "    Result.append(TVD_temp)\n",
    "    print('Current direction TVD of DGM is: ', TVD_temp)\n",
    "    TVD_DGM = TVD_DGM + TVD_temp\n",
    "    print((count + 1) / M * 100, '% finished.')\n",
    "\n",
    "# print('Max of all is: ', np.max(Max))\n",
    "# print('Min of all is: ', np.min(Min))\n",
    "\n",
    "TVD_DGM = TVD_DGM / M \n",
    "print('All directions average TVD of DGM is: ', TVD_DGM)\n",
    "\n",
    "print('Variance TVD of DGM is: ', np.sqrt(np.var(Result, ddof = 1)))\n",
    "\n",
    "time_end = time.time()\n",
    "print('Total time costs: ', time_end - time_start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt \n",
    "import matplotlib.pyplot as mp\n",
    "import numpy as np\n",
    "plt.style.use(\"seaborn-dark\") # print(plt.style.available)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirc = [i + 1 for i in range(len(Result))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt \n",
    "import matplotlib.pyplot as mp\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(\"seaborn-dark\")\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "ax.set_ylim(0.999, 1.0)\n",
    "\n",
    "plt.scatter(dirc, Result, c = 'green')\n",
    "plt.xlabel('Direction index', size = 12)\n",
    "plt.ylabel('TV', size = 12)\n",
    "plt.grid(True)\n",
    "# plt.savefig(\"Relative_error.eps\", dpi = 120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('DGM.npy', Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
